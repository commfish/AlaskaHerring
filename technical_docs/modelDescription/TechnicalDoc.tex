\documentclass[12pt,letterpaper]{article}

% Use utf-8 encoding for foreign characters
\usepackage[utf8]{inputenc}

% Setup for fullpage use
\usepackage{fullpage}
\usepackage{lscape}

% Uncomment some of the following if you use the features
%
% Running Headers and footers
\usepackage{fancyhdr}

% Multipart figures
%\usepackage{subfigure}

% Multicols
\usepackage{multicol}
\setlength{\columnseprule}{0.5pt}
\setlength{\columnsep}{15pt}

% More symbols
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{bm}

% Surround parts of graphics with box
\usepackage{boxedminipage}

% Longtables
\usepackage{longtable}

% Package for including code in the document
\usepackage{listings}
\usepackage{alltt}

% If you want to generate a toc for each chapter (use with book)
% \usepackage{minitoc}

% This is now the recommended way for checking for PDFLaTeX:
\usepackage{ifpdf}

% Natbib
\usepackage[round]{natbib}


%% -math-
\def\bs#1{\boldsymbol{#1}}

\newcounter{saveEq}
  \def\putEq{\setcounter{saveEq}{\value{equation}}}
  \def\getEq{\setcounter{equation}{\value{saveEq}}}
  \def\tableEq{ % equations in tables
    \putEq \setcounter{equation}{0}
    \renewcommand{\theequation}{T\arabic{table}.\arabic{equation}}
    \vspace{-5mm}
    }
  \def\normalEq{ % renew normal equations
    \getEq
    \renewcommand{\theequation}{\arabic{section}.\arabic{equation}}}

  \def\puthrule{ %thick rule lines for equation tables
    \hrule \hrule \hrule \hrule \hrule}

% Hyperref
% \usepackage{url}
\usepackage[colorlinks,bookmarks,citecolor=magenta,linkcolor=blue]{hyperref}
% \usepackage{hyperref}

%\newif\ifpdf
%\ifx\pdfoutput\undefined
%\pdffalse % we are not running PDFLaTeX
%\else
%\pdfoutput=1 % we are running PDFLaTeX
%\pdftrue
%\fi

\ifpdf
\usepackage[pdftex]{graphicx}
\else
\usepackage{graphicx}
\fi
\graphicspath{{./figs/}}



% \usepackage{tikz-uml}


\title{Age-structured model for Alaska herring stocks}
\author{Steve Martell}



% my macros
\newcommand{\fspr}{$F_{\textnormal{SPR}}$}
\newcommand{\bspr}{$B_{\textnormal{SPR\%}}$}

\newcommand{\fmsy}{$F_{\textnormal{MSY}}$}
\newcommand{\bmsy}{$B_{\textnormal{MSY}}$}

\newcommand{\ham}{HAM}


\begin{document}
  \maketitle
  \renewcommand{\abstractname}{Executive Summary}
  \begin{abstract}
    This document describes the proposed changes that have been made to the Age-structured assessment model for Alaska herring stocks. 

    The objective of this project was to review and modify the existing AD Model Builder Code for the Age-structured model for Alaska herring stocks (version 0.1 Jan 2015).  The overarching objective of the modifications are:  to improve numerical stability, ease of use, general flexibility for alternative structural assumptions, and estimation of observation and process error variance to better quantify uncertainty. The following list of bullets summarizes the proposed changes that have been implemented to date:

    \begin{itemize}
      \item Modifications to the Input Data File.  Users can now specify estimates of observation error for each annual observation for: catch, egg surveys, mile milt days, and composition data.
      \item Modifications to the Control file.  Changes to the control file now allow users to estimate or fix parameters, change the phase of estimation, set initial parameter values, apply informative priors of various statistical distributions, all without having to recompile the code.  This permits rapid exploration (even automated) of alternative hypotheses and structural assumptions that are repeatable.
      \item Added controls for the addition of time varying natural mortality rates, blocks of time-varying maturity, a flexible system from implementing a wide variety of selectivity options including time-varying blocks, or continuous non-parametric functions (i.e., cubic splines). The control file is also structured so it can expand with new model features, or custom outputs, that develop in the future.
      \item Custom command line options were added to the code. Two options were added to permit rapid simulation testing (\texttt{-sim} option), and automate the procedures of conducting retrospective analysis without having to make any potentially dangerous modifications to input files (the \texttt{-retro }option). 
      \item Many of the previous routines in the current version of the stock assessment model have been broken down into smaller functions.  This both reduces the amount of redundant code that currently exists and makes the code easier to read and understand by humans.
      \item The model has 5 major components:
        \begin{enumerate}
          \item Inputs (includes data and controls that specifies model structure).
          \item Population dynamics: a collection of sub-models that relate to the biology (e.g., natural mortality, maturity, stock-recruitment).
          \item Observation dynamics: a collection of sub-models that relate how fishing mortality interacts with population model (e.g., fisheries selectivity, fishing mortality, predicted egg abundance index, predicted composition data).
          \item Statistical criterion: the objective function that relates estimated model parameters to differences between observed and predicted variables.
          \item Outputs: including and not limited to parameter estimates, convergence criterion, derived management quantities and residuals.
        \end{enumerate}
      \item There are a few structural differences being proposed in this model that relate to how selectivity is modeled, the observation error assumed in the composition data, and variance terms that relate to both process error and observation error.
        \begin{itemize}
          \item To avoid breaking the derivative chain in calculating the objective function and its gradient, use of the max function to re-scale the selectivities should be avoided.  Often you can get away with it in very simple models where selectivity is very well informed, but can soon become problematic when your jointly estimating additional parameters that are confounded with selectivity (e.g., time-varying natural mortality).  To do so, the proposed change rescales the selectivity vector for ages such that it has a mean of 1. 
          \item The previous generation used a least-square estimator for the age-composition proportions. The proposed changes implemented in this model assume the age-proportion data are logistic-normal, and these data are weighted by the conditional maximum likelihood estimate of the variance (i.e., objectively weighted).  Alternatives likelihood formulations are also easily implemented in future iterations.
          \item Lastly, each catch and survey observation in the input data file also has an associated log standard error associated with it (approximately the coefficient of variation).  In cases where it is possible to estimate a standard error in the data using bootstrap procedures, the inter-annual variation in observation error can now be specified.  In addition, the process error term permits recruitment variation around a stock-recruitment relationship. Currently the Ricker model is implemented, with the option to implement the Beverton-Holt model annotated in the code. 
        \end{itemize}
        \item Additional elements were also introduced in the objective function calculation to improve the overall estimation robustness.  These include penalties that are only implemented in the initial phases to set up initial gradients that will get key population parameters in the ``ball park''. These penalties can then be relaxed (or set = 0) in  the terminal phases.
        \item Of significant difference is the use of informative prior distributions (or sometimes less informative) for population parameters including: natural mortality, initial recruitment, average recruitment, unfished recruitment, steepness of the stock recruitment relationship, and the variance in the recruitment deviations (process error).  The only option for including priors in the previous generation was to fix a parameter value (which implies the variance is 0, or very informative).  For example, having the option to estimate natural mortality where the prior mean is set at the original fixed value and assume some arbitrary CV can often reduce model confounding in cases where there are one-way trips in the relative abundance data. Comparing the marginal posterior density and prior density will shed light on how informative the data are about the parameters.
        \item Model selection criterion can also be evaluated using  Deviance Information Criterion (DIC).  This criterion is calculated using the posterior sample values generated from one of AD Model Builders built-in sampling routines (e.g., The Metropolis Hastings Algorithm).
    \end{itemize}

    Lastly, a few R-scripts have been developed for the purposes of conducting simulation-estimation experiments for self-testing to examine for potential bias in the estimators, and exploring options for correcting any such bias.

    An example assessment using the data for the 2015 Sitka herring stock is provided in this document. This example is not meant to be used as a comparison with other assessments for this stock. The intent of the example is to be illustrative.  Finally, the scope of this project focused on the aforementioned points above, and primarily focuses on data weighting and estimation of uncertainty. There are many other graphical methods that could be explored to further communicate levels of uncertainty to fisheries managers, and I would refer you to the work of Dr. Ian Stewart at the Intl. Pacific Halibut Commission on communicating uncertainty to decision makers.


  \end{abstract}

  \section{Acknowledgments} % (fold)
  \label{sec:acknowledgments}
    I greatly appreciate the feedback from the State of Alaska scientists who participated in the training workshop in Juneau Alaska, July 27-29, 2016.  A special thank  you to Dr. Sherri Dressel for organizing this workshop and inviting me to bid on this contract. 
  % section acknowledgments (end)

  \tableofcontents

  \section{Introduction} % (fold)
  \label{sec:introduction}

  This document describes the structural differences between the Age-structured model for Alaska herring (programmed by Pete Hulson, pete.hulson@noaa.gov). The original model was written in Excel, and translated to the AD Model Builder template language.  The objective function was a simple weighted least-squares estimator that made numerous simplifying assumptions about the error structure in the data.  The objective for the next generation of stock assessment models for Alaska herring stocks is to use a  more modern statistical approach to fitting models to data collected from fisheries dependent and independent sources.  

  In this document we first decompose the original source code to understand how the various observations are related to structural assumptions in the model, and how these data are weighted when estimating model parameters.  Next we describe a technical description of the proposed model changes, and provide both the equations and the AD Model Builder template code to document how the equations are actually implemented in the code.  A simple example of a simulation-estimation experiment exploring estimation performance (i.e., precision and bias) is explained from both  an observation and mixed observation-process error model. Following, a simple example of fitting the model to the Sitka herring stock using the example Sitka data and control files that are available in the code repository.  

  Having both the equations and the code serve a dual purpose, first it provides model documentation and second allows for new programmers to learn more about the language itself and implement changes to accommodate alternative structural assumptions. The model code is intended to be a living document, and I would encourage developers to use use the code repository, create branches and add or modify the existing code to tailor the model for specific  applications or research projects.
  
  % section introduction (end)

  \section{Model deconstruction} % (fold)
  \label{sec:model_deconstruction}
  This section is intended to serve three purposes: 1) to document the model structure given the code in model.tpl,  2) to detail proposed changes to the model code to improve overall numerical stability, and 3) provide a statistical approach that is amenable to maximum likelihood and Bayesian methods.

    \subsection{Model Structure} % (fold)
    \label{sub:model_structure}
    
    Table \ref{tab:ModelDeconstruction} begins with the objective function that is being minimized in the original Alaska herring model programmed by Pete Hulson.   There are four components defined in \eqref{eq.f}, where three of the four components are scaled by user defined coefficients $\lambda$.  The first component is the commercial age-composition data ($QC$), the second is the spawning biomass age-composition ($QS$), the third is egg deposition data ($WQE$), and finally the fourth component is a penalty on the recruitment deviations from the underlying Ricker stock-recruitment model ($QR$).

    For the commercial age-composition data, observation errors in the age-proportions are assumed to be normal \eqref{eq.SSQC}, where the predicted proportion-at-age \eqref{eq.Qij} is a function of the numbers-at-age \eqref{eq.Vij} and selectivity \eqref{eq.Sij}. Note that in \eqref{eq.Vij} that the function is not continuous. In this case the selectivity curve is rescaled to have a maximum value of 1.0. The \texttt{max} operation in the denominator of this function breaks the derivative chain in AD Model Builder and can result in numerical problems during parameter optimization associated with corrupt derivative information. 

    The same normal error distribution is also assumed for the age-proportions in the spawner catch composition samples \eqref{eq.QS}.  In this case, the age proportions are based on the mature numbers-at-age at the time of spawning, where the fishery removals are first subtracted from the mature numbers-at-age \eqref{eq.Oij}.  Note that this further assumes that all removals (i.e., fisheries selectivity) only harvests sexually mature fish.  This assumption is inconsistent with \eqref{eq.Vij}, where a different logistic curve is assumed for fisheries selectivity.  



    \begin{table}[ht]
      \centering
      \caption{Decomposition of the objective function based on the source code provided in \texttt{model.tpl}. The objective function $f$ is what AD Model Builder is trying to minimize. Note that $\dot{}$ represents mature state variables (e.g., mature weight-at-age $\dot{w}_j$)}
      \label{tab:ModelDeconstruction}
      \tableEq
      \begin{align}
        \hline \nonumber
        &\mbox{Objective function} & \nonumber\\
        & f = \lambda_C QC + \lambda_S QS + WQE + \lambda_R QR & \label{eq.f} \\[1ex]
        %%
        &\mbox{Commercial catch proportion-at-age}  \nonumber\\
        & QC = \sum_i \sum_j (\hat{Q}_{i,j} - Q_{i,j})^2 & \mbox{$\hat{Q}_{i,j}$ observed proportions-at-age} \label{eq.SSQC}\\
        & Q_{i,j} = \frac{V_{i,j}}{\sum_j V_{i,j}} & \mbox{$Q_{i,j}$ predicted proportion-at-age} \label{eq.Qij} \\
        & V_{i,j} = N_{i,j} \frac{S_{i,j}}{\max(S_{i,j})} & \mbox{$V_{i,j}$ vulnerable numbers-at-age} \label{eq.Vij}\\
        & S_{i,j} = \frac{1}{1+\exp(-g_i(j-a_i))} &\mbox{$S_{i,j}$ Selectivity in year $i$ for age $j$} \label{eq.Sij} \\[1ex]
        %%
        %%
        &\mbox{Spawn proportion-at-age} \nonumber\\
        & QS = \sum_i \sum_j (\hat{O}_{i,j}-O_{i,j})^2 &  \mbox{$\hat{O}_{i,j}$ observed proportion-at-age} \label{eq.QS}\\
        & O_{i,j} = \frac{\dot{N}_{i,j}}{\sum_j \dot{N}_{i,j} } & \mbox{$O_{i,j}$ predicted proportion mature-at-age} \label{eq.Oij}\\
        & \dot{N}_{i,j} = N_{i,j} M_{i,j} - C_{i,j} & \mbox{$\dot{N}_{ij}$  Number-at-age at spawning} \\
        & C_{i,j} = \frac{\hat{c}_i Q_{i,j}}{\sum_j Q_{i,j} w_j} & \mbox{$\hat{c}_i$ observed catch, $w_j$ weight-at-age} \label{eq.Cij}\\[1ex]
        %%
        %%
        &\mbox{Egg deposition survey} \nonumber\\
        & WQE = \sum_i \varphi_i\left[ \ln(\hat{y}_i)-\ln(y_i) \right]^2 & \mbox{$\hat{y}_i$ observed egg deposition, $\varphi_i$ weight}\label{eq.WQE}\\
        & y_i = 0.5 \sum_j O_{i,j} (\rho_i \dot{w}_{i,j}-\alpha_i) &\mbox{$\rho_i$ and $\alpha_i$ fecundity-weight regression} \\
        %%
        %%
        &\mbox{Penalized recruitment deviations} \nonumber \\
        & QR = \sum_{i}^{(I-k)} \left[  \ln\left(N_{i+k,k}\right) 
        - \ln\left(f(\dot{N}_{i,j}) \right) \right]^2 
          & \mbox{$N_{i+k,k}$ number of age $k$ recruits}\\
        & f(\dot{N}_{i,j}) = a \dot{B}_i \exp(-b \dot{B}_i) &\mbox{Ricker stock-recruitment}\\
        & \dot{B}_i = \sum_j \dot{N}_{i,j} \dot{w}_j &\mbox{$\dot{B}_i$ mature biomass at spawning} \\
      %   %%
        \hline \nonumber
      \end{align}
      \normalEq
    \end{table}
    The catch-at-age data is internally derived in the model \eqref{eq.Cij} conditional on the numbers-at-age and the estimated selectivity. The model further assumes the total catch (in short tons) is measured without error.  This is also referred to as conditioning the model on catch.

    The residual sum of squares for the egg deposition survey is given by \eqref{eq.WQE}.  In this case the observation errors are assumed to be log-normal, and each year's observation is weighted by the inverse variance of sampling observation errors ($\varphi_i$).

    % subsection model_structure (end)

  % section model_deconstruction (end)


  \clearpage
  \section{Technical description of the proposed model changes} % (fold)
  \label{sec:methods}
  
  \subsection{Input Data} % (fold)
  \label{sub:input_data}
    The best resource for looking at the input data is the html file that describes the input data. There are 7 major sections to the data file.
    \begin{enumerate}
      \item Model dimensions.
      \item Fecundity regression coefficients.
      \item Total Annual Catch.
      \item Empirical Weight-at-age (spawn and commercial).
      \item Age-composition (spawn and commercial).
      \item Egg deposition data.
      \item Mile milt days.
    \end{enumerate}

    These are the same data inputs that were used in the ASA model; however, there have a been a number of significant changes to the input data file.  The most significant change is the addition of the log standard error for each catch, egg deposition, and spawn survey observation.  
  % subsection input_data (end)

  \subsection{Control file} % (fold)
  \label{sub:control_file}
    There are also significant changes to the control file.  In fact, it's a completely different control file than what was used in the ASA model.  Again, the best resource for looking at the specific contents of the control file is the control file itself. 


    To highlight some of the major changes, the control file now consists of a design matrix for controlling the leading model parameters; specifically, the bounds and phases in which these parameters are estimated.  There is a block for time-varying maturity, a block for time-varying natural mortality rate deviations, a block for selectivity, where the user can choose among alternative parametric and non-parametric selectivity curves. Lastly, there is a vector of other miscellaneous model controls for, \textit{inter Alia}, re-scaling catch, conditioning the model on catch or effort.  

  % subsection control_file (end)

  \subsection{Age-schedule information} % (fold)
  \label{sub:age_schedule_information}
    Empirical weight-at-age data are part of the input data file.  Maturity-at-age is assumed to follow a logistic function with age, where the parameters of the logistic function are estimated within the model. 

    
    \subsubsection{Maturity-at-age} % (fold)
    \label{ssub:maturity_at_age}
      For the maturity-at-age, the \ham\ assumes that age-specific maturity follows a logistic relationship, where the estimated parameters define the age-at-50\% maturity and the standard deviation, for each unique block period (the block periods are user defined). 

       The source code for the TPL file is as follows:
       \lstset{basicstyle=\footnotesize}
      \lstinputlisting[language=C++, firstline=807, lastline=822]{../../src/ham.tpl}
      where \texttt{plogis} is a built in ADMB function for the logistic: \[f(x) =  (1+\exp(-(x-\mu)/\sigma))^{-1} \] where $\mu$ and $\sigma$ are the location and scale parameters that are estimated.
    
    % subsubsection maturity_at_age (end)

    \subsubsection{Natural mortality} % (fold)
    \label{ssub:natural_mortality}
    
      Natural mortality is both age- and time-specific.  At the time of writing, there is no code that allows for age-dependent natural mortality, but this option is easily added as a feature to the \ham.

      The source code for the TPL file is as follows:
      \lstinputlisting[language=C++, firstline=825, lastline=854]{../../src/ham.tpl}
      where the Matrix $M_{i,j}$ is the instantaneous natural mortality rate for year $i$ and age $j$.  At this point the code just fills each row of the matrix with the same annual natural mortality rate (i.e., age-independent).  This is where you would want to modify the code to allow for age-dependent natural mortality rates.
    % subsubsection natural_mortality (end)

    \subsubsection{Selectivity} % (fold)
    \label{ssub:selectivity}
      Currently only the logistic selectivity option is implemented. But the source code is structured such that alternative parametric and non-parametric functions can be easily added to the source code using a switch statement.

       The source code for the TPL file is as follows:
      \lstinputlisting[language=C++, firstline=858, lastline=888]{../../src/ham.tpl}

      The matrix $S_{i,j}$ is the relative selectivity for age $j$ in year $i$.  Additional functions for computing the vector \texttt{slx} can be new cases (e.g. case 2:  // coefficients).

      In this model,  selectivity is parameterized to have a mean value of 1.0.  The reason for this particular parameterization is to ensure the objective function remains continuous and differentiable.  In each year, the vector of age-specific selectivity coefficients is scaled to have a mean value of 1.0, rather than have an asymptote of 1.0.  This is accomplished, in log-space, by subtracting the mean from the vector of age-specific selectivities.  This avoids having to use the max function; the use of the max function can lead to a discontinuity in the objective function which result in non-convergence.  The trade-off for this numerical stability is that the interpretation of fishing mortality rates changes.  The estimator is calculating the average-age-specific fishing mortality rate.  The fully-selected fishing mortality rate is more commonly used metric, and this is easily accommodated post-estimation by re-scaling the vector of fishing mortality rates by the maximum age-specific selectivity in each year. 

      Note that the trends in the mean fishing mortality rates already integrates the changes in selectivity over time. These estimates of F probably better reflect the measure of fishing effort (i.e., mile-hours fished). Whereas, asymptotic estimates reflect the trends in fishing mortality rates for ``fully recruited'' cohorts and are less likely to reflect fishing intensity.
    % subsubsection selectivity (end)

  % subsection age_schedule_information (end)

  \subsection{Fishing mortality} % (fold)
  \label{sub:fishing_mortality}
  If the model is conditioned on effort, then a routine that calculates the age-specific fishing mortality rate is invoked.  In this routine, a vector of fishing mortality rate parameters, in log-space, is estimated, and the age-specific fishing mortality rate is the product of the fishing rate and age-specific selectivity.  The source code for this routine is as follows:
  \lstinputlisting[language=C++, firstline=891, lastline=898  ]{../../src/ham.tpl}

  If the model is conditioned on catch (i.e., the method the ASA model uses), then there is a resulting difference equation which has the potential to result in negative numbers-at-age, which results in negative infinity in log-space.  To guard against this, a simple solution might be to use a max function to ensure that a positive number is returned. However, this is yet another occurrence where the objective function is discontinuous and subject to non-convergence issues.  AD Model Builder has a function \texttt{posfun} that can be used to ensure the objective function remains continuous and differentiable.
  % subsection fishing_mortality (end)


  \subsection{Population dynamics} % (fold)
  \label{sub:population_dynamics}
  Estimated parameters for the population dynamics model include the initial abundance of ages 3-9+ for the initial year, abundance of age-3 recruits each year, and the natural mortality rate. In the original parameterization of the model, these initial recruitments and the vector of initial numbers-at-age result in creating $(N + A-1)$ scaling parameters.  To reduce the potential confounding with other global scaling parameters, updates to the model code include estimation of two recruitment scaling parameters, and two vectors that represent deviations from the mean. This modification reduces the potential for parameter confounding among the many parameters that affect global scaling (i.e., catchability coefficients, natural mortality rates, average recruitment or unfished biomass).

    
  

  

  \begin{table}[h]
    \centering
    \caption{Notation and equations for population dynamics model.}
    \label{tab:PopulationDynamics}
    \tableEq
    \begin{align}
      \hline \nonumber
      & \mbox{Model parameters} & \nonumber\\
      & \theta = \{\ln(M),\ln(\bar{R}),\ln(\ddot{R}), 
        \ln(\alpha),\ln(\beta),\vec{\delta} \} \\[1ex]
      %%
      & \mbox{Initial States ($i=1980$)} \nonumber \\
      & \iota_j = \begin{cases}
          \exp(-M*(j-\mbox{min}(j))) & \quad \mbox{where } 3 \leq j \leq 7 \\[1ex]
          \dfrac{\exp(-M*(j-\mbox{min}(j)))}{1-\exp(-M)} & \quad \mbox{where } j=8 \\
          \end{cases} & \mbox{survivorship} \label{eq.survivorship}\\[1ex]
      & N_{i,j} = \ddot{R} \exp(\delta_{i-j}) \iota_j \qquad \qquad  i=1980,\forall j & \mbox{initial numbers-at-age} \label{eq.initialnumbersatage} \\
      & N_{i,j} = \bar{R} \exp(\delta_i) \qquad  \quad \qquad \quad \forall i, j=3 & \mbox{age-3 recruits} \label{eq.initialrecruits} \\[1ex]
      %%
      & \mbox{Dynamic States ($i > 1980$)} \nonumber\\
      & Q_{i,j} = \frac{N_{i,j} S_{i,j}}{\sum_j N_{i,j} S_{i,j}} &\mbox{vulnerable proportions} \label{eq.predQij} \\
      & \bar{w}_i  = \sum_j w_j  Q_{i,j} &\mbox{average weight of catch} \\
      & C_{i,j} = \frac{\hat{c}_{i}Q_{i,j}}{\bar{w}_i} \qquad \mbox{where $\hat{c}_i$ is the observed catch (mt)} &\mbox{$C_{i,j}$ catch-at-age} \\
      & \acute{N}_{i,j} = N_{i,j} \exp(-F_{i,j}) \\
      & N_{i+1,j+1} = \acute{N}_{i,j} \exp(-M_{i,j}) \\[1ex]
      %%
      & \mbox{Spawning stock biomass} \nonumber\\
      & B_{i} = \sum_j (N_{ij}-C_{ij}) \omega_{ij} w_j & \mbox{Spawning stock biomass} \label{eq.ssb}\\
      & \mbox{Stock-recruitment} \nonumber\\
      \hline \nonumber
      %%
    \end{align}
    \normalEq
  \end{table}

  \subsubsection{Initial state variables.} % (fold)
    \label{ssub:initial_state_variables_}
    
    In this routine, the objective is to set the initial values for the numbers-at-age matrix $N_{i,j}$.  Specifically, the row dimensions of the matrix are from the start year to the terminal year + 1, the column dimensions are the ages.  This routine first calculates the survivorship to age $j$ based on natural mortality rates, then initializes the first row of $N_{i,j}$ matrix using the average initial recruitment and deviations around that average recruitment multiplied by the survivorship at age $j$.  The source code also includes the Taylor series for the plus group:
    \lstinputlisting[language=C++, firstline=902, lastline=929]{../../src/ham.tpl}

    The survivorship calculation \texttt{lx} corresponds to \eqref{eq.survivorship} in Table \ref{tab:PopulationDynamics}, and the numbers-at-age in the initial year and age-3 recruits corresponds to \eqref{eq.initialnumbersatage} and \eqref{eq.initialrecruits}, respectively.
    % subsubsection initial_state_variables_ (end)

    \subsubsection{Update state variables} % (fold)
    \label{ssub:update_state_variables}
    In this routine, the numbers-at-age are propagated in time, where the-age specific survival rate is partitioned into two periods: a fishing period, and a period of natural mortality.  The ASA model currently in use for Sitka Sound herring assumes a pulse fishery.  At the start of each time step, the model first calculates the predicted catch-at-age in numbers in year $i$. This is done by first converting the catch-in-weight to catch-in-numbers using the predicted average weight of the catch.  This corresponds to the \texttt{wbar} variable in the following code chunk (note the dependency on predicted proportions-at-age):
    \lstinputlisting[language=C++, firstline=934, lastline=999]{../../src/ham.tpl}
    Once the catch-at-age data is calculated, the pulse fishery proceeds by subtracting the $C_{ij}$  from the $N_{i,j}$.  The last two steps correspond to step 4 in the annotated code chunk. The last steps the survive the remaining numbers-at-age using the natural mortality rate in year $i$. Then finally, update the numbers-at-age $j$ to $j+1$ in year $i$ to year $i+1$, including the plus group for the terminal age-group.
    % subsubsection update_state_variables (end)

    \subsubsection{Stock-recruitment \& Spawning stock biomass} % (fold)
    \label{ssub:stock_recruitment_&_spawning_stock_biomass}
    The spawning stock biomass (after roe-fishery removal) is the product of the remaining numbers-at-age, the maturity-at-age, and the weight-at-age from spawn samples.  The equation is defined in \eqref{eq.ssb} in Table \ref{tab:PopulationDynamics}.  Note that the lag between spawning biomass and age-3 recruits is taken into account.

    The stock recruitment relationship assumes that recruitment follows a Ricker type.  The form  of the Ricker model is as follows \[ R_i = s_o B_i \exp(-\beta B_i + \epsilon_i)\] where the parameter $s_o$ is the slope at the origin (or maximum number of recruits per spawning unit), and $\beta$ defines slope of $\ln(R_i/B_i)$ versus the independent variable $B_i$.  These two parameters are derived from the leading parameters the unfished recruitment $R_0$ and the steepness of the stock recruitment relationship as defined by \citep{mace1988generalised}.

    The source code for the stock-recruitment relationship is well annotated and describes some of the derivations:
    % \begin{small}
    \lstinputlisting[language=C++, firstline=1005, lastline=1073]{../../src/ham.tpl}
      
    % \end{small}

    There is an issue with regards to calculating reference points in cases where there is non-stationarity (i.e., any time varying parameters such as natural mortality, maturity etc.).  At what period should be used to define the average weight-at-age for spawning herring? What period should be used for calculating the average maturity?  All of these are subjective decisions, and based on my experience will have little impact on the overall fit to the data, but could have major implications for harvest policy changes. 

    % subsubsection stock_recruitment_&_spawning_stock_biomass (end)
  % subsection population_dynamics (end)

  \subsection{Observation models} % (fold)
  \label{sub:observation_models}
    \subsubsection{Age composition} % (fold)
    \label{ssub:age_composition}
    The predicted age-composition is based on the vulnerable proportions at age $Q_{i,j}$ in \eqref{eq.predQij}.  The residual difference is used to compute the negative log likelihood in the objective function.  The code for the age composition residual calculation is as follows:
    \lstinputlisting[language=C++, firstline=1077, lastline=1098]{../../src/ham.tpl}
    Note that both the residual difference between the commercial and spawning samples are calculated in this routine.  If there are missing data for a given year (denoted by a -9.0 in the data file), then the residual difference is set to 0 for that year and there is no contribution to the negative log likelihood.
    % subsubsection age_composition (end)

    \subsubsection{Egg deposition} % (fold)
    \label{ssub:egg_deposition}
    The observation model for the egg deposition data treats these observations as estimates of absolute abundance.  Therefore, there is no associated scaling parameter that is estimated. The observation errors in the egg deposition data are assumed to be log-normal.  The predicted age-deposition data is based on the female (assuming a 50:50 sex ratio) mature numbers-at-age multiplied by the fecundity at age.  The annotated source code is as follows:
    \lstinputlisting[language=C++, firstline=1102, lastline=1117]{../../src/ham.tpl}

    % subsubsection egg_deposition (end)

    \subsubsection{Aerial surveys} % (fold)
    \label{ssub:aerial_surveys}
    The aerial survey index, or mile milt days, are treated as relative abundance data.  The underlying assumption in this observation model is that the observation errors are log normal, and that the index is proportional to the spawning stock biomass.  Note that the code does not estimate the coefficient, rather the conditional maximum likelihood estimate of the scaling coefficent is used \citep[see][for a full explanation]{walters1994calculation}.  The annotated code follows:
     \lstinputlisting[language=C++, firstline=1119, lastline=1139]{../../src/ham.tpl}
    % subsubsection aerial_surveys (end)

    \subsubsection{Predicted catch} % (fold)
    \label{ssub:predicted_catch}
    In the case where the model is conditioned on effort and fitted to the catch time series data, the predicted catch is the sum of products between the catch-at-age in numbers and the observed weight-at-age in the commercial fishery.
    We further assume observation errors are log-normal. The source code follows:
    \lstinputlisting[language=C++, firstline=1142, lastline=1153]{../../src/ham.tpl}
    % subsubsection predicted_catch (end)
  % subsection observation_models (end)

  \subsection{Objective function} % (fold)
  \label{sub:objective_function}
  The objective function is organized into two sections, the first contains the negative log-likelihoods for the data given the model parameters.  The second are a series of penalties, in the case of maximum likelihood estimation, prior density functions in the case of a Bayesian estimation.
    \subsubsection{Negative log-likelihoods} % (fold)
    \label{ssub:negative_loglikelihoods}
    The negative log-likelihoods 
    % subsubsection negative_loglikelihoods (end)
    There are five 6 negative log-likelihoods functions in the objective function that correspond to the 5 different data elements and the residual process errors associated with a stock-recruitment relationship. Table \ref{tab:likelihoodOptions} summarizes the available options currently implemented.

    \begin{table}[h]
      \caption{Data and types of likelihoods implemented}
      \label{tab:likelihoodOptions}
      \begin{tabular}{l|c|c|c|c}
        \hline
        Data & normal & log-normal & multivariate-logistic & multinomial\\
        \hline
        Commercial Age-comps & & & X\\
        Spawn Survey Age-comps & & & X\\
        Egg deposition & & X & \\
        Aerial survey & & X  & \\
        Catch  & & X & \\
        Stock-Recruitment & & X & \\
      \end{tabular}
    \end{table}

    The source code for the negative loglikelihoods follows:
    \lstinputlisting[language=C++, firstline=1165, lastline=1195]{../../src/ham.tpl}
    
    For the composition data, the multivariate logistic likelihood is currently implemented, as this is a self-scaling likelihood.  A good reference for this particular likelihood and how it's implemented in AD Model Builder can be found in \cite{schnute1995influence}.  More recent work on the weighting of composition data is available in \cite{francis2011data}.  The function \texttt{dmvlogistic} requires 5 arguments: the observed and predicted composition matrices, a matrix for returning the residuals, a variable for the conditional MLE of the variance of the observation errors, and a threshold value called \texttt{minp}. The multivariate logistic likelihood does not accommodate 0 observations for age proportions.  Therefore there are two options for dealing with 0s: 1) add a small constant to all observed and predicted observations and re-normalize, or 2) pool the adjacent cohorts if the observed proportion is less than some minimum observed proportion.  The first option is widely used in programs such as stock synthesis, and is akin to manufacturing data.  If a particular cohort is relatively weak, and only partially selected, the sample size required to observe just one individual of a certain age in a given year could be infinitely large.  Instead of adding a constant, option 2 pools the data such that the likelihood of ages, for example, 3-4 are evaluated jointly, rather than the likelihood of age-3 plus the likelihood of age-4.  This pooling of the data and predictions does not require the addition of a constant that could potentially bias the result.  A good practice that I've found is to just set \texttt{minp=0}, and then conduct sensitivity tests using where proportions less than 1\% or 2\% etc are pooled into the adjacent cohort.

    In the case of the likelihoods for the egg deposition index, aerial surveys, and catch data, the function \texttt{dnorm} is used, where the arguments are the vector of residuals, and a vector of standard-deviations for each observation.  Note that you can effectively turn individual years of data off by setting the \texttt{log.se} value to a large number (e.g., 5.0).

    The current version of the source code will estimate an annual fishing mortality rate for each year (when the model is conditioned on effort only).  This can become problematic in the case where the catch is 0 for a particular year.  A technical point in cases where the catch is 0. In this case the MLE for the fishing mortality rate is also 0, but the derivative is undefined because the observed standard deviation is also 0.  In such cases, estimates of the standard error for the fishing mortality rate in a year with 0 catch will be undefined.  One option to explore for simulation studies (i.e., when using the -sim argument) is to modify the original data file and add a small, insignificant amount, of catch to ensure the simulation model generates some data, otherwise spurious results may occur in  simulation studies.

    \subsubsection{Penalties} % (fold)
    \label{ssub:penalties}
    Currently the code for the penalties is as follows:
    \lstinputlisting[language=C++, firstline=1173, lastline=1190,breaklines=true,basicstyle=\footnotesize]{../../src/ham.tpl}

    The penalties are implemented in a phased approach, where in the initial phases of parameter estimation, the penalties initially have small standard deviations. This increases the overall efficiency of the non-linear search routine to help resolve the overall scaling. Then in the terminal phase, these penalties are relaxed (increased variance) such that they provide little or no influence on the gradient structure.  A similar strategy is also used with the recruitment deviation parameters.
    % subsubsection penalties (end)
  % subsection objective_function (end)
% \begin{table}
%   \centering
%   \caption{Mathematical notation, symbols and descriptions.}
%   \label{tab:notation}
%   \begin{tabular}{cl}
%   \hline
%   Symbol  & Description \\
%   \hline
%   \multicolumn{2}{l}{\underline{Index}}\\
%       $g$ & group \\
%       $h$ & sex \\
%       $i$ & year \\
%       $j$ & time step (years) \\
%       $k$ & gear or fleet \\
%       $l$ & index for length class \\
%       $m$ & index for maturity state \\
%       $o$ & index for shell condition. \\
%   \multicolumn{2}{l}{\underline{Leading Model Parameters}}\\
%       $M$         & Instantaneous natural mortality rate\\
%       $\bar{R}$   & Average recruitment\\
%       $\ddot{R}$  & Initial recruitment\\
%       $\alpha_r$  & Mode of size-at-recruitment\\
%       $\beta_r $  & Shape parameter for size-at-recruitment\\
%       $R_0$       & Unfished average recruitment\\
%       $\kappa$    & Recruitment compensation ratio\\
%   \multicolumn{2}{l}{\underline{Size schedule information}}\\
%       $w_{h,l}$   & Mean weight-at-length $l$ \\
%       $m_{h,l}$   & Average proportion mature-at-length $l$ \\
%   \multicolumn{2}{l}{\underline{Per recruit incidence functions}} \\
%       $\phi_B$    & Spawning biomass per recruit \\
%       $\phi_{Q_k}$& Yield per recruit for fishery $k$\\
%       $\phi_{Y_k}$& Retained catch per recruit for fishery $k$ \\
%       $\phi_{D_k}$& Discarded catch per recruit for fishery $k$ \\
%   \multicolumn{2}{l}{\underline{Selectivity parameters}} \\
%       $a_{h,k,l}$ & Length at 50\% selectivity in length interval $l$\\
%       $\sigma_{s_{h,k}}$ & Standard deviation in length-at-selectivity\\
%       $r_{h,k,l}$ & Length at 50\% retention\\
%       $\sigma_{y_{h,k}}$ & Standard deviation in length-at-retention\\
%       $\xi_{h,k}$ & Discard mortality rate for gear $k$ and sex $h$\\
%   \hline
%   \end{tabular}
% \end{table}


  
  \section{Simulation example} % (fold)
  \label{sec:simulation_example}
  
  Built into the assessment model code is a command line option that conducts a simulation experiment.  In this experiment, the input parameter values are known, and simulated observations are generated with known error distributions. The model then proceeds to estimate the model parameters using built-in optimization procedures.  Any potential biases can be detected by comparing the estimated values with the true values. This is best done using a Monte Carlo experiment where the distributions of estimated parameters are compared with the true values used in simulating the data.

  For this simulation example, the data from the Sitka herring stock will be used. I first fit the model to the Sitka data to obtain the following parameter input file. Next, save this file as \texttt{ham.pin}, and by default the model will read these parameters when the application is first initialized. These parameters saved in the \texttt{ham.pin} file can be modified to specific values defined by the user.  

  \lstinputlisting[language=R, firstline=1, lastline=30,breaklines=true,basicstyle=\tiny]{../../models_2015/sitka/sim0.pin}

  Next, run the model using the \texttt{-sim} flag using the number 1 as the random number seed.  At the command line you can run:

  \texttt{./ham -sim 1}

  When you execute the above command, the following sequence summarizes the events that occur inside the simulation model:
  \begin{enumerate}
    \item Set random number seed for random variables.
    \item Read in the model data.
    \item Read in the initial parameter values from \texttt{ham.par}.
      \item Run the simulation model:
    \begin{enumerate}
    \item Call the population dynamics subroutines.
    \item Call the observation models to generate predicted observations.
    \item Add random errors to the simulated observations.
    \item Overwrite the input data in memory with the simulated data.
    \end{enumerate}
    \item After the simulated data has been created, the model proceeds with its normal routines for conducting parameter estimation.
    \item Simulated observations are printed to the report file. 
    \item Estimated parameters in the \texttt{ham.par} file should be comparable with the true parameter (\texttt{ham.pin}) values that were used in generating the simulated data.
  \end{enumerate}

  This approach to simulation-estimation is called ``self-testing'' where both the same model is used to generate the data, as well as, in fitting the model to data. Arguably, this approach should generate exact parameter estimates in the case where data are generated with no simulated observation errors.

  \subsection{Observation error} % (fold)
  \label{sub:observation_error_only_simulations}
  
   For the purposes of demonstration, Figure \ref{fig.SimulatedSSB} shows the results of conditioning the simulation model on the Stika herring data. In these simulation-estimation experiments, all of the simulations were conditioned on the same fishing mortality rates and recruitment vectors that were estimated from fitting the model to the Sitka data. The only difference between the 8 simulation models are the random numbers in the observation errors.  

   The simple test should result in estimates of spawning stock biomass and fishing mortality rates that fall within the 95\% confidence interval that was used to generate the data.  The results in Figures \ref{fig.SimulatedSSB} and \ref{fig.SimulatedFs} indicate that this is in fact the case. 


  \begin{figure}
    \label{fig.SimulatedSSB}
    \centering
    \includegraphics[height=\textwidth]{SitkaSimulationSSBs.png}
    \caption{Estimates of spawning stock biomass where only the observation errors differ among simulations. Shaded region corresponds to the 95\% credible interval for the true distribution of spawning biomass, and the colored lines correspond to estimates based on simulated observations in the egg survey and catch-age sampling.}
  \end{figure}  

  \begin{figure}
    \label{fig.SimulatedFs}
    \centering
    \includegraphics[height=\textwidth]{SitkaSimulationFs.png}
    \caption{Estimates of the instantaneous fishing mortality rates where the only observation errors differ among simulations. Shaded region corresponds to the 95\% credible interval for the true distribution of fishing mortality, and the colored lines correspond to estimates based on simulated observations in the egg survey and catch-age sampling.}
  \end{figure}


  % subsection observation_error_only_simulations (end)

  \subsection{Mixed error} % (fold)
  \label{sub:mixed_error_simulations}
  
  In a mixed error model, the model includes process errors in the form of deviations from average recruitment, and these are drawn from a normal distribution with a mean 0 and standard deviation equal to $\sigma_R$.  When conducting simulations of this type, the model is conditioned on the instantaneous fishing mortality rates that are specified in the parameter input file (\texttt{ham.pin}) if the file exists in the current working directory. If a parameter input file does not exist, then the initial values specified in the control file are used for the leading model parameters and the annual instantaneous fishing mortality rates are set at a default value of 0.2 each year.

  It's important to note here that the scaling parameters (initial recruitment and average recruitment) are sufficiently large such that the population is not driven to extinction based on the initial parameter values.  Moreover, the current iteration of the simulation model generates recruits from an average recruitment and log-normal deviations.  As such, the simulated data are not informative about the underlying stock-recruitment relationship.  Additional modifications should be made to the simulation model, where the expected value of recruitment in each simulation year is a function of $R_0$ and the steepness (or slope at the origin) of the stock-recruitment relationship.

  No mixed error simulations are shown in this technical document, but the same procedure as outlined in section \ref{sub:observation_error_only_simulations} is used to conduct the simulation experiments.



  % subsection mixed_error_simulations (end)

  % section simulation_example (end)


  \section{Example Assessment: Sitka herring} % (fold)
  \label{sec:example_assessment_sitka_herring}
  
  For this example, the data from the Sitka herring stock were used in this assessment.  This example is just that, an example. This is not intended to be used for any decision making purposes.


  \subsection{Input data} % (fold)
  \label{sub:input_data}
  
  The catch data shown in Figure~\ref{fig:SitkaCatch} are shown with the estimated 95\% confidence intervals associated with the log standard error associated in the input data file.  For this example the assessment model is conditioned on effort, which simply means a vector of fishing mortality rates are estimated by fitting the model to the observed catch.  The previous assessment simply subtracted the catch, which implies the catch is known and assumed to have no measurement error. 



  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{SitkaCatch.png}
    \caption{Herring removals from the Sitka stock. Error bars are based on the log standard error defined in the input data file.}
    \label{fig:SitkaCatch}
  \end{figure}

  The primary index for fitting this model is the survey egg deposition data. The time series for the Sitka herring stock is shown in Figure~\ref{fig:SitkaEggIndex} and are plotted on a logarithmic scale.  There has been nearly a 10-fold increase in this index between 1970's and the 2010's.  Note that the model assumes a 50:50 sex ratio, and the data are scaled in trillions of eggs, assuming the catch is in metric tons.


  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{SitkaLogEggIndex.png}
    \caption{Egg survey index for Sitka herring. Note that these data are plotted on a log scale.}
    \label{fig:SitkaEggIndex}
  \end{figure}


  The empirical weight-at-age data for the spawn survey are shown in Figure~\ref{fig:SitkaWeightAtAge}).  The commercial weight-at-age data are shown in Figure~\ref{fig:SitkCmWeighAtAge}. These are user input data and are used to convert numbers-at-age to weight-at-age.

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{SitkaWeightAtAge.png}
    \caption{Empirical weight-at-age data for Sitka spawn survey.}
    \label{fig:SitkaWeightAtAge}
  \end{figure}

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{SitkCmWeightAtAge.png}
    \caption{Empirical weight-at-age data for Sitka Commercial fishery samples.}
    \label{fig:SitkCmWeighAtAge}
  \end{figure}

  Figures \ref{fig:SitkaSpAgeComps} and \ref{fig:SitkaCmAgeComps} are bubble plots showing the proportions-at-age in the age-composition data for the spawn survey samples and the commercial samples, respectively. Each distinct color represents a specific cohort over time, and the area of each circle is proportional to abundance.

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{SitkaSpAgeComps.png}
    \caption{Age-proportions by year from the spawn survey samples.}
    \label{fig:SitkaSpAgeComps}
  \end{figure}  

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{SitkaCmAgeComps.png}
    \caption{Age proportions by year from the commercial fishery samples.}
    \label{fig:SitkaCmAgeComps}
  \end{figure}

  \clearpage
  % subsection input_data (end)














  \subsection{Model outputs} % (fold)
  \label{sub:model_outputs}

  Model output from the age-structured herring model are stored in a number of output files that are produced automatically by ADMB. The maximum likelihood estimates (MLE) of model parameters with standard deviations and correlations are found in the \texttt{ham.cor} file. User defined outputs are in the \texttt{ham.rep} file, and if you wish to add additional outputs that currently do not exist, these outputs can be added to the \texttt{REPORT\_SECTION} of the tpl file and the code must be recompiled.  

  The following output figures were generated from a series of R-scripts (available on the project repository) that were developed during the course of model development.

  Estimates of mature spawning stock biomass (male and female combined based on the maturity ogive) are shown in Figure \ref{fig:ssb}, along with the approximate 95\% confidence interval.


  
  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/ssb.png}
    \caption{Estimates of mature spawning biomass at the time of spawning, (post-fishery) and the 95\% confidence interval shown in the shaded region.}
    \label{fig:ssb}
  \end{figure}

  Estimates of the average annual instantaneous fishing mortality rates each year are shown in Figure \ref{fig:ft}.  Recall that age-specific selectivity each year is scaled to have a mean value of 1.0 to ensure both parametric and non-parametric selectivity models remain continuous and differentiable.  If asymptotic estimates of fishing mortality rates are desired, then the series shown in Fig. \ref{fig:ft} is multiplied by the maximum selectivity each year.  

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/ft.png}
    \caption{Estimates of the mean instantaneous fishing mortality rate with the 95\% confidence interval.}
    \label{fig:ft}
  \end{figure}

  Figure \ref{fig:Fcompare} compares the trends in the asymptotic fishing mortality rates versus the average fishing mortality rate.  The trends in the asymptotic estimates of fishing mortality suggests that fishing mortality rates have been increasing in recent years, but this trend is associated with changes in selectivity, where younger age-classes are becoming less vulnerable to the gear.  To examine this issue further you would look for changes in selectivity over time where older age-classes are more selected that younger age-classes.  

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/Sitka_Fcompare.png}
    \caption{Trends in average age-specific fishing mortality rates versus the asymptotic trends in fishing mortality rate. The trends differ slightly due to changes in selectivity over time.}
    \label{fig:Fcompare}
  \end{figure}

  Again, in this example the stock assessment model is conditioned on fishing effort. This means that a vector of annual fishing mortality rates are estimated by jointly fitting the model to the observed catch data (Figure \ref{fig:ctfit}).  This differs significantly from the previous model version where the observed catch was assumed to be measured without error, and removed from the population using a difference equation. 

  The residual difference between the observed and predicted catch is shown in Figure \ref{fig:resd_cct}.  In this case the residuals appear to have a non-random pattern that emerges due to the minor differences between the trends in F associated with the catch and abundance index, and the trends in Z that are inferred from the age-composition data.  Furthermore, the pattern changes from random from 1970-1979, to all negative from 1980 to 1999, and flips to positive from 2000 to 2015.  These blocks also correspond to the selectivity blocks in the control file for the Sitka herring stock.

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/ctfit.png}
    \caption{Observed and predicted catch in the Sitka herring fishery.}
    \label{fig:ctfit}
  \end{figure}

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/resd_cct.png}
    \caption{Residual fit to the commercial catch data.}
    \label{fig:resd_cct}
  \end{figure}

  The primary information that the model is being fit to is the egg deposition index (Figure \ref{fig:logegg}).  The egg deposition survey data are treated as absolute abundance information.  In other words there is no additional scaling parameter that is estimated for the purposes of comparing only trend information.  These data provide information about population scaling, so units associated with catch, weight-at-age, and maturity, are critical.

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/logegg.png}
    \caption{Fits to the egg survey index for Sitka herring. Note these data and predictions are plotted on a log scale.}
    \label{fig:logegg}
  \end{figure}

  The residuals for the egg deposition pattern are shown in Figure \ref{fig:resd_egg}.  The model is not able to fit the 1988, 1994, and 2008 survey data points (corresponding to the largest 3 residuals).

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/resd_egg.png}
    \caption{Residual fit to the egg deposition data.}
    \label{fig:resd_egg}
  \end{figure}


  Another feature built into the assessment model is to jointly fit a stock-recruitment model to the estimated age-3 recruits and estimated spawning biomass.  This could also be done outside the model, but the resulting estimates of uncertainty in reference points would be biased because uncertainty in the independent variable (spawning biomass) is not propagated. The residual fit to a Ricker stock-recruitment curve is shown in Figure \ref{fig:resd_rec}.


  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/resd_rec}
    \caption{Residual deviations between the log of annual age-3 recruits and the Ricker stock recruitment relationship.}
    \label{fig:resd_rec}
  \end{figure}

  Residual fits to the catch-at-age data for the spawn survey samples are shown in Figure \ref{fig:resd_csp}.  The area of each circle is proportional to the residual difference between the observed catch-at-age proportion and the predicted catch-at-age proportion. The residual patterns for the commercial age-composition proportions is shown in Figure \ref{fig:resd_ccm}. Ideally, the pattern of residuals would be completely random with respect to both age and time dimensions.  Some patterns to watch out for that could be a sign of model-misspecification are blocks of residuals all of the same sign (+ve or -ve) that might be indicative of a change in behavior or a change in regulations that result in a behavioral change.

  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/resd_csp.png}
    \caption{Residual fits to the spawn survey age composition data.}
    \label{fig:resd_csp}
  \end{figure}


  \begin{figure}[tb]
    \centering
    \includegraphics[height=\textwidth]{./figs/resd_ccm.png}
    \caption{Residual fits to the commercial age composition data.}
    \label{fig:resd_ccm}
  \end{figure}

  
  \clearpage
  % subsection model_outputs (end)

  % section example_assessment_sitka_herring (end)

  \section{Summary} % (fold)

  Although age-structured models tend to estimate dozens, if not 100s, of more parameters than the simple surplus production or biomass dynamics models, The key policy parameters that define stock productivity and scale (i.e., intrinsic rate of growth and carrying capacity) only involve 3 basic parameters, unfished stock size, natural mortality, and the steepness of the stock-recruitment relationship.  Estimates of unfished biomass, or its analogue unfished recruitment, defines the population scaling. This parameter is primarily informed by the scale of the catch data.  The natural mortality rate defines ``residency'', or the number of years and average individual will persist in the population and survive to contribute to future generations via spawning events.  Trend information in composition data can jointly inform natural mortality rates in a stock assessment model, but these estimates are also conditional on structural assumptions about model selectivity.  The steepness of the stock recruitment relationship is more related to population resilience, but in this case we are specifically referring to how strong the density-dependent juvenile survival rate from egg to age-3 recruit is. The stronger the compensatory response is, the more resilient the stock is to the effects of fishing.

  If reliable estimates of unfished stock size,  natural mortality rates, and the steepness of the stock recruitment relationship can be obtained from the age-structured assessment model, then fisheries reference points can easily be developed conditional on assumptions about fisheries selectivity. The code herein readily provides the means to calculate MSY or SPR-based reference points.  Furthermore, uncertainty in these reference points can also be quantified by either sampling from the joint posterior distribution and computing a distribution for MSY, or FMSY.  Or use the delta method to obtain asymptotic estimates of uncertainty using the inverse of the Hessian matrix (e.g., an \texttt{sdreport\_number} in ADMB).

  A number of significant changes were introduced into this new code, with the primary goals of: improving numerical stability, providing a more modern statistical framework for  quantifying uncertainty, and changes to the data input and control files to allow for rapid exploration of alternative model structures without having to recompile the code, or have several versions of the code, that are all prone to programmer errors.  I've also tried to provide comments in the code that direct a programmer or the next generation of analyst to add additional options for selectivity, or different stock-recruitment curves and, alternative likelihood functions for composition data.  This is an active area of research in fisheries stock assessment, and the documented code provides an interface in which to explore alternatives.

  As an example of flexibility, let's say a reviewer wanted to know how the assessment model differs if you were to treat the egg survey index as a relative index instead of absolute. One option that does not involve making any changes to the code, is to put the egg index in the mile milt day input.  In this case, the model will only fit the trends in the egg abundance rather than treating them as absolute.  More importantly, no potentially dangerous code changes were necessary to make the comparisons.

  Below are  some of the major structural differences and  a few warnings to the user to watch out for.  For example: is the objective function continuous and differentiable, how to avoid getting stuck in local minima, is fishing mortality really increasing or is selectivity just changing?

  The previous age-structured model for Alaska herring stocks assumed the catch was known without error.  In this parameterization each year the observed catch was subtracted from the mature spawning biomass using a difference equation. One potential pitfall with this approach is that during the non-linear optimization to find the maximum likelihood estimates of the model parameters, it is possible that the population can go negative.  In such circumstances, the search routine can easily get stuck in local minima because the gradient of the objective function is not continuous.  My recommendation is not to condition the model on catch, but to fit the model to the catch and estimate the fishing mortality rates directly.


  When allowing estimated model parameters to vary over time (e.g., time-varying selectivity, or time-varying natural mortality rates), estimated trends in the asymptotic fishing mortality rates may differ slightly with trends in the average fishing mortality.  The fishing mortality rates may appear to be stable, but this statement is only true if trends in selectivity are also invariant over the same time period. 

  Lastly, if you feel confident that the data are informative such that you would like to try and estimate the variance parameter for the recruitment deviations ($\sigma_R$), you'll likely discover that the model may tend to converge to either an observation error only model (i.e., $\sigma_R \rightarrow 0$), or less likely a process error only model (only if the user specifies very small observation errors in the data file).  There are a number of options that might be considered to address this statistical ``errors-in-variables'' problem.  The simplest approach is jointly estimate  an additional variance term (a feature commonly implemented in Stock Synthesis), or preferably integrate over the random variables (recruitment deviations) using numerical methods (e.g., MCMC).  For example, a common observation is that MLE estimates of $\sigma_R$ in this model will be less than the median estimates of $\sigma_R$ obtained from random samples of the joint posterior distribution.  If the data are not that informative, or there is a lot of conflicting data or model misspecification that leads to greater uncertainty, informative priors for $\sigma_R$ will probably be required to obtain convergence.  The alternative to MCMC is a mixed-effects, or random-effects, models which are becoming more popular in the last 5 years.
  \label{sec:summary}
  
  % section summary (end)



  \bibliographystyle{apalike}
  \bibliography{$HOME/Documents/ARTICLES/Articles-1}

\end{document}
